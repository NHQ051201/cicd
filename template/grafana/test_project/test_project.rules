groups:
- name: test_project # change to correct one
  rules:

  # Alert for any instance that is unreachable for >2 minutes.
  - alert: AppDown
    expr: sum(node_systemd_unit_state{job=~"node-test-.*-apps.?", state="active", name=~"(?i:(.*Prod).*)"}) by (name) == 0
    for: 2m
    labels:
      severity: 'critical'
      project: 'test_project' # change to correct one
    annotations:
      summary: "App {{ $labels.name }} down"
      description: "{{ $labels.name }} of job {{ $labels.job }} has been down for more than 2 minutes."
      dashboard_url: "http://grafana:3000" # change to correct one

  - alert: AppRestart
    expr: sum(node_systemd_service_restart_total{job=~"node-test-.*-apps.?", name=~"(?i:(.*Prod).*)"}) by (name) > 0
    for: 2m
    labels:
      severity: 'critical'
      project: 'test_project' # change to correct one
    annotations:
      summary: "App {{ $labels.name }} is crashing"
      description: "{{ $labels.name }} is crashing."
      dashboard_url: "http://grafana:3000" # change to correct one

  - alert: RmqQueueMessagesHigh
    expr: rabbitmq_queue_messages{job=~"node-test-.*-services.?", queue=~"deposit_balance|deposit_incoming" } >= 50
    for: 2m
    labels:
      severity: 'critical'
      project: 'test_project' # change to correct one
    annotations:
      summary: "High amount of Rmq messages for {{ $labels.job }}"
      description: "{{ $labels.job }} High RMQ msgs."
      dashboard_url: "http://grafana:3000" # change to correct one

  - alert: RmqQueueMessagesHigh
    expr: sum(rabbitmq_queue_messages_ready{job=~"node-test-.*-services.?"}) >= 8000
    for: 2m
    labels:
      severity: 'critical'
      project: 'test_project' # change to correct one
    annotations:
      summary: "High amount of Rmq messages for {{ $labels.job }}"
      description: "{{ $labels.job }} High RMQ msgs."
      dashboard_url: "http://grafana:3000" # change to correct one
